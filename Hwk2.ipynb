{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation du réseau de neurones et expérimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Implémentation de fonctions utiles\n",
    "Calcul numériquement stable du softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_vector(x):\n",
    "    '''\n",
    "    x:  is a data vector.\n",
    "    returns: the result of the softmax function applied to the data vector.\n",
    "    '''\n",
    "    max_comp = np.amax(x)\n",
    "    normalized  = x - max_comp\n",
    "    \n",
    "    exponential = np.exp(normalized)\n",
    "    \n",
    "    return exponential/np.sum(exponential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    '''\n",
    "    X: matrix that holds the data, every row is a data vector.\n",
    "    returns: matrix where every row is the result of the softmax function applied to the corresponding data vector.\n",
    "    '''\n",
    "    \n",
    "    max_comp = np.amax(X, axis=1)\n",
    "    normalized  = X - max_comp.reshape(X.shape[0], 1)\n",
    "    \n",
    "    exponential = np.exp(normalized)\n",
    "    \n",
    "    return exponential/np.sum(exponential, axis=1).reshape(X.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction utilitaire pour calculer relu($x$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, np.zeros(x.shape))\n",
    "\n",
    "def onehot(m, y):\n",
    "    return np.eye(m)[y]\n",
    "\n",
    "def onehot_matrix(m, targets):\n",
    "    \"\"\"\n",
    "    Returns: onehot matrix where every column is a onehot vector of the coressponding target\n",
    "    \"\"\"\n",
    "    eye = np.eye(m)\n",
    "    onehot_matrix = np.zeros((m,len(targets)))\n",
    "    \n",
    "    for i, y in enumerate(targets):\n",
    "        onehot_matrix[:,i] = eye[y]\n",
    "        \n",
    "    return onehot_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calcul du gradient sur un exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation de fprop et bprop pour calculer le gradient sur un exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNet_basic:\n",
    "    \n",
    "    def __init__(self, n_input, n_hidden, n_out):\n",
    "        \n",
    "        self.n_in = n_input\n",
    "        self.n_h = n_hidden\n",
    "        self.n_o = n_out\n",
    "        \n",
    "        low_bound = -1 / np.sqrt([self.n_in, self.n_h])\n",
    "        up_bound = 1 / np.sqrt([self.n_in, self.n_h])\n",
    "        \n",
    "        # Initialize the parameters\n",
    "        self.W1 = np.random.uniform(low_bound[0], up_bound[0], size=(self.n_h, self.n_in))  # d_h x d\n",
    "        self.W2 = np.random.uniform(low_bound[1], up_bound[1], size=(self.n_o, self.n_h))  # m x d_h\n",
    "        self.b1 = np.zeros(self.n_h)  # dimension d_h\n",
    "        self.b2 = np.zeros(self.n_o) # dimension m\n",
    "    \n",
    "    def fprop(self, x):\n",
    "        '''Computes activations for every layer'''\n",
    "        self.ha = self.W1.dot(x) + self.b1\n",
    "        self.hs = relu(self.ha)\n",
    "        self.oa = self.W2.dot(self.hs) + self.b2\n",
    "        self.os = softmax_vector(self.oa)\n",
    "            \n",
    "    def bprop(self, x, y):\n",
    "        '''Computes the gradients, must be executed after fprop'''\n",
    "                      \n",
    "        grad_oa = self.os - onehot(self.n_o, y)\n",
    "        grad_b2 = grad_oa\n",
    "        grad_W2 = np.outer(grad_oa, self.hs)\n",
    "        grad_hs = self.W2.T.dot(grad_oa)\n",
    "        grad_ha = grad_hs * (self.ha > 0)\n",
    "        grad_W1 = np.outer(grad_ha, x)\n",
    "        grad_b1 = grad_ha\n",
    "        \n",
    "        return grad_W1, grad_W2, grad_b1, grad_b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vérification du gradient par différences finies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant vérifier que le gradient calculé est juste. Pour cela on va calculer une approximation du gradient en utilisant la méthode de la différence finie.\n",
    "\n",
    "Pour chaque composante de w1, on va:\n",
    " 1. calculer la valeur de la fonction objectif $L$\n",
    " 2. ajouter une petite valeur $\\epsilon$ à la composante\n",
    " 3. recalculer la valeur de la fonction objectif $L'$\n",
    " 4. remettre à l'ancienne valeur la composante (c'est à dire soustraire $\\epsilon$)\n",
    "\n",
    "Le gradient par différences finies sera dans ce cas donné par:\n",
    "$\\Big( \\frac{\\partial L}{\\partial W_{1}} \\Big)_{ij} = \\frac{1}{\\epsilon} (L' - L)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(x, y, W1, W2, b1, b2):\n",
    "    ha = W1.dot(x) + b1\n",
    "    hs = relu(ha)\n",
    "    oa = W2.dot(hs) + b2\n",
    "    os = softmax_vector(oa)\n",
    "    \n",
    "    return -np.log(os[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour calculer le gradient par differences finies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finite_diff(x, y, neural_net, eps=1e-5):\n",
    "    \n",
    "    # params\n",
    "    W1 = neural_net.W1\n",
    "    W2 = neural_net.W2\n",
    "    b1 = neural_net.b1\n",
    "    b2 = neural_net.b2\n",
    "    \n",
    "    # gradients\n",
    "    grad_w1_diff = np.zeros(W1.shape)\n",
    "    grad_w2_diff = np.zeros(W2.shape)\n",
    "    grad_b1_diff = np.zeros(b1.shape)\n",
    "    grad_b2_diff = np.zeros(b2.shape)\n",
    "    \n",
    "    neural_net.fprop(x)\n",
    "    loss = compute_loss(x, y, W1, W2, b1, b2)\n",
    "    \n",
    "    for i in range(W1.shape[0]):\n",
    "        for j in range(W1.shape[1]):\n",
    "            W1[i,j] = W1[i,j] + eps\n",
    "            loss_prime = compute_loss(x, y, W1, W2, b1, b2)\n",
    "            grad_w1_diff[i, j] = (loss_prime - loss) / epsilon\n",
    "            W1[i,j] = W1[i,j] - eps\n",
    "    for i in range(W2.shape[0]):\n",
    "        for j in range(W2.shape[1]):\n",
    "            W2[i,j] = W2[i,j] + eps\n",
    "            loss_prime = compute_loss(x, y, W1, W2, b1, b2)\n",
    "            grad_w2_diff[i, j] = (loss_prime - loss) / epsilon\n",
    "            W2[i,j] = W2[i,j] - eps\n",
    "    for i in range(b1.shape[0]):\n",
    "            b1[i] = b1[i] + eps\n",
    "            loss_prime = compute_loss(x, y, W1, W2, b1, b2)\n",
    "            grad_b1_diff[i] = (loss_prime - loss) / epsilon\n",
    "            b1[i] = b1[i] - eps\n",
    "    for i in range(b1.shape[0]):\n",
    "            b2[i] = b2[i] + eps\n",
    "            loss_prime = compute_loss(x, y, W1, W2, b1, b2)\n",
    "            grad_b2_diff[i] = (loss_prime - loss) / epsilon\n",
    "            b2[i] = b2[i] - eps\n",
    "            \n",
    "    return grad_w1_diff, grad_w2_diff, grad_b1_diff, grad_b2_diff\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage de vérification du gradient par différence finie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(open('2moons.txt','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Différence entre les deux gradients pour W1, W2, b1, b2:\n",
      "[[ -5.58324467e-10  -1.32355634e-08]\n",
      " [  0.00000000e+00  -0.00000000e+00]]\n",
      "[[ -8.72016346e-08  -0.00000000e+00]\n",
      " [ -8.72033004e-08   0.00000000e+00]]\n",
      "[ -4.11289126e-09   0.00000000e+00]\n",
      "[ -1.24994118e-06  -1.24992580e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNet_basic(2, 2, 2)\n",
    "x = data[0,:-1]\n",
    "y = data[0,-1]\n",
    "epsilon = 1e-5\n",
    "\n",
    "# gradients par différence finie\n",
    "grad_w1_diff, grad_w2_diff, grad_b1_diff, grad_b2_diff = finite_diff(x, y, nn, epsilon)\n",
    "\n",
    "# gradients par implémentation dans classe neural_net\n",
    "grad_W1, grad_W2, grad_b1, grad_b2 = nn.bprop(x,y)\n",
    "\n",
    "# affichage de la différence\n",
    "print('Différence entre les deux gradients pour W1, W2, b1, b2:')\n",
    "#print(grad_w1_diff)\n",
    "#print(grad_W1)\n",
    "print(grad_W1 - grad_w1_diff)\n",
    "print(grad_W2 - grad_w2_diff)\n",
    "print(grad_b1 - grad_b1_diff)\n",
    "print(grad_b2 - grad_b2_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ajout de hyperparamètre de taille de lot K\n",
    "La fonction bprop est modifiée pour calculer le gradient sur un batch d'exemple. La fonction train est également ajoutée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNet_loop:\n",
    "    \n",
    "    def __init__(self, n_input, n_hidden, n_out, lambdas, K = 1):\n",
    "        \n",
    "        self.n_in = n_input\n",
    "        self.n_h = n_hidden\n",
    "        self.n_o = n_out\n",
    "        self.K = K\n",
    "        self.lambdas = lambdas\n",
    "        \n",
    "        low_bound = -1 / np.sqrt([self.n_in, self.n_h])\n",
    "        up_bound = 1 / np.sqrt([self.n_in, self.n_h])\n",
    "        \n",
    "        np.random.seed(123)\n",
    "        \n",
    "        # Initialize the parameters\n",
    "        self.W1 = np.random.uniform(low_bound[0], up_bound[0], size=(self.n_h, self.n_in))  # d_h x d\n",
    "        self.W2 = np.random.uniform(low_bound[1], up_bound[1], size=(self.n_o, self.n_h))  # m x d_h\n",
    "        self.b1 = np.zeros(self.n_h)  # dimension d_h\n",
    "        self.b2 = np.zeros(self.n_o) # dimension m\n",
    "    \n",
    "    def fprop(self, x):\n",
    "        '''Computes activations for every layer'''\n",
    "        ha = self.W1.dot(x) + self.b1\n",
    "        hs = relu(ha)\n",
    "        oa = self.W2.dot(hs) + self.b2\n",
    "        os = softmax_vector(oa)\n",
    "        return ha, hs, oa, os\n",
    "            \n",
    "    def bprop(self, X, Y):\n",
    "        '''Computes the gradients over all examples in (X,Y) with loop'''\n",
    "        grad_W1_mean = np.zeros((self.n_h, self.n_in))\n",
    "        grad_W2_mean = np.zeros((self.n_o, self.n_h))\n",
    "        grad_b1_mean = np.zeros(self.n_h)\n",
    "        grad_b2_mean = np.zeros(self.n_o)\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        loss = 0.\n",
    "        \n",
    "        for i in range(n):\n",
    "            \n",
    "            ha, hs, oa, os = self.fprop(X[i,:])\n",
    "            loss += -np.log(os[Y[i]])\n",
    "            \n",
    "            grad_oa = os - onehot(self.n_o, Y[i])\n",
    "            grad_b2 = grad_oa\n",
    "            grad_W2 = np.outer(grad_oa, hs)\n",
    "            grad_hs = self.W2.T.dot(grad_oa)\n",
    "            grad_ha = grad_hs * (ha > 0)\n",
    "            grad_W1 = np.outer(grad_ha, X[i,:])\n",
    "            grad_b1 = grad_ha\n",
    "            \n",
    "            grad_W1_mean = grad_W1_mean + grad_W1 / n\n",
    "            grad_W2_mean = grad_W2_mean + grad_W2 / n\n",
    "            grad_b1_mean = grad_b1_mean + grad_b1 / n\n",
    "            grad_b2_mean = grad_b2_mean + grad_b2 / n\n",
    "        \n",
    "        return grad_W1_mean, grad_W2_mean, grad_b1_mean, grad_b2_mean, loss \n",
    "    \n",
    "    def compute_loss(self, x, y):\n",
    "        _, _, _, os = self.fprop(x)\n",
    "        return -np.log(self.os[y])\n",
    "    \n",
    "    def train(self, train_data, max_iter, eta=0.05):\n",
    "        \n",
    "        n_batches = int(np.ceil(train_data.shape[0]/self.K)) # number of batches\n",
    "        \n",
    "        # Initialize batch start and end indices\n",
    "        \n",
    "        for i in range(max_iter):\n",
    "            loss = 0.\n",
    "            for j in range(0,train_data.shape[0],self.K):\n",
    "                batch = train_data[j:j+self.K]\n",
    "                \n",
    "                grad_W1_mean, grad_W2_mean, grad_b1_mean, grad_b2_mean, bloss = self.bprop(batch[:,:-1], batch[:,-1]) \n",
    "                loss += bloss\n",
    "                \n",
    "                n = len(batch)\n",
    "                \n",
    "                #regularization\n",
    "                penality_grad_W1 = self.lambdas[0][0] * np.sign(self.W1) + 2 * self.lambdas[0][1] * self.W1\n",
    "                penality_grad_W2 = self.lambdas[1][0] * np.sign(self.W2) + 2 * self.lambdas[1][1] * self.W2\n",
    "                \n",
    "                self.W1 = self.W1 - eta * (grad_W1_mean + penality_grad_W1)\n",
    "                self.W2 = self.W2 - eta * (grad_W2_mean + penality_grad_W2)\n",
    "                self.b1 = self.b1 - eta * grad_b1_mean\n",
    "                self.b2 = self.b2 - eta * grad_b2_mean\n",
    "                \n",
    "            if i%100 == 0:\n",
    "                print('The loss after epoque ', i, ' is ', loss / train_data.shape[0])\n",
    "                    \n",
    "    def compute_predictions(self, test_data):\n",
    "\n",
    "        pred = np.empty((test_data.shape[0],self.n_o))\n",
    "\n",
    "        for i in range(test_data.shape[0]):\n",
    "            _, _, _, os = self.fprop(test_data[i,:])\n",
    "            pred[i,:] = os\n",
    "\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vérification du gradient par différence finie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage de vérification du gradient pour un lot de 10 exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Différence entre les deux gradients pour W1, W2, b1, b2\n",
      "[[ -1.37831296e-08  -1.77901403e-07]\n",
      " [ -4.38070745e-08  -1.18092063e-07]]\n",
      "[[ -1.41384634e-07  -4.08140944e-08]\n",
      " [ -1.41384729e-07  -4.08172739e-08]]\n",
      "[ -6.75580648e-08  -6.82009196e-08]\n",
      "[ -1.24341350e-06  -1.24341613e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:43: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.array([[0, 0],\n",
    "       [0, 0]])\n",
    "nn = NeuralNet_loop(2, 2, 2, lambdas)\n",
    "X = data[0:10,:-1]\n",
    "Y = data[0:10,-1]\n",
    "\n",
    "# params\n",
    "W1 = nn.W1\n",
    "W2 = nn.W2\n",
    "b1 = nn.b1\n",
    "b2 = nn.b2\n",
    "\n",
    "# gradients par différence finie\n",
    "grad_w1_diff = np.zeros(W1.shape)\n",
    "grad_w2_diff = np.zeros(W2.shape)\n",
    "grad_b1_diff = np.zeros(b1.shape)\n",
    "grad_b2_diff = np.zeros(b2.shape)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    grad_w1, grad_w2, grad_b1, grad_b2 = finite_diff(X[i,:], Y[i], nn, epsilon)\n",
    "    grad_w1_diff += grad_w1 / X.shape[0]\n",
    "    grad_w2_diff += grad_w2 / X.shape[0]\n",
    "    grad_b1_diff += grad_b1 / X.shape[0]\n",
    "    grad_b2_diff += grad_b2 / X.shape[0]\n",
    "    \n",
    "# gradients par implémentation dans classe neural_net    \n",
    "grad_W1, grad_W2, grad_b1, grad_b2, _ = nn.bprop(X,Y)\n",
    "\n",
    "# affichage de la différence\n",
    "print('Différence entre les deux gradients pour W1, W2, b1, b2:')\n",
    "#print(grad_w1_diff)\n",
    "#print(grad_W1)\n",
    "print(grad_W1 - grad_w1_diff)\n",
    "print(grad_W2 - grad_w2_diff)\n",
    "print(grad_b1 - grad_b1_diff)\n",
    "print(grad_b2 - grad_b2_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entraînement sur 2 moons et visualisation des régions de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction de calcul du taux d'erreur de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cette fonction renvoie le taux d'erreur étant donné un classifieur et un ensemble de données\n",
    "def taux_erreur(classifieur, data):\n",
    "    x = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "    data_prob = classifieur.compute_predictions(x)\n",
    "    data_classe_pred = np.argmax(data_prob, axis=1)\n",
    "    \n",
    "    return 100. * np.mean(data_classe_pred != y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'affichage des régions de décision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fonction plot\n",
    "import pylab\n",
    "def gridplot(classifieur,train,test,n_points=50):\n",
    "\n",
    "    train_test = np.vstack((train,test))\n",
    "    (min_x1,max_x1) = (min(train_test[:,0]),max(train_test[:,0]))\n",
    "    (min_x2,max_x2) = (min(train_test[:,1]),max(train_test[:,1]))\n",
    "\n",
    "    xgrid = np.linspace(min_x1,max_x1,num=n_points)\n",
    "    ygrid = np.linspace(min_x2,max_x2,num=n_points)\n",
    "\n",
    "\t# calcule le produit cartesien entre deux listes\n",
    "    # et met les resultats dans un array\n",
    "    thegrid = np.array(combine(xgrid,ygrid))\n",
    "\n",
    "    les_comptes = classifieur.compute_predictions(thegrid)\n",
    "    classesPred = np.argmax(les_comptes,axis=1)+1\n",
    "\n",
    "    # La grille\n",
    "    pylab.pcolormesh(xgrid, ygrid, classesPred.reshape((n_points, n_points)).T, alpha=.3)\n",
    "\t# Les points d'entrainment\n",
    "    pylab.scatter(train[:,0], train[:,1], c = train[:,-1], marker = 'v', s=50)\n",
    "    # Les points de test\n",
    "    pylab.scatter(test[:,0], test[:,1], c = test[:,-1], marker = 's', s=50)\n",
    "\n",
    "    ## Un petit hack, parce que la fonctionalite manque a pylab...\n",
    "    h1, = pylab.plot([min_x1], [min_x2], marker='o', c = 'w',ms=5) \n",
    "    h2, = pylab.plot([min_x1], [min_x2], marker='v', c = 'w',ms=5) \n",
    "    h3, = pylab.plot([min_x1], [min_x2], marker='s', c = 'w',ms=5) \n",
    "    handles = [h1,h2,h3]\n",
    "    ## fin du hack\n",
    "\n",
    "    labels = ['grille','train','test']\n",
    "    pylab.legend(handles,labels)\n",
    "\n",
    "    pylab.axis('equal')\n",
    "    pylab.show()\n",
    "    \n",
    "## http://code.activestate.com/recipes/302478/\n",
    "def combine(*seqin):\n",
    "    '''returns a list of all combinations of argument sequences.\n",
    "for example: combine((1,2),(3,4)) returns\n",
    "[[1, 3], [1, 4], [2, 3], [2, 4]]'''\n",
    "    def rloop(seqin,listout,comb):\n",
    "        '''recursive looping function'''\n",
    "        if seqin:                       # any more sequences to process?\n",
    "            for item in seqin[0]:\n",
    "                newcomb=comb+[item]     # add next item to current comb\n",
    "                # call rloop w/ rem seqs, newcomb\n",
    "                rloop(seqin[1:],listout,newcomb)\n",
    "        else:                           # processing last sequence\n",
    "            listout.append(comb)        # comb finished, add to list\n",
    "    listout=[]                      # listout initialization\n",
    "    rloop(seqin,listout,[])         # start recursive process\n",
    "    return listout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement sur les données 2 moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(732, 3)\n",
      "(368, 3)\n",
      "The loss after epoque  0  is  0.742051488932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:43: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after epoque  100  is  0.352166076737\n",
      "The loss after epoque  200  is  0.169644528383\n",
      "The loss after epoque  300  is  0.0919171896489\n",
      "The loss after epoque  0  is  0.685970885965\n",
      "The loss after epoque  100  is  0.0919368402694\n",
      "The loss after epoque  200  is  0.0409311253808\n",
      "The loss after epoque  300  is  0.0292997626117\n",
      "The loss after epoque  0  is  0.644463699343\n",
      "The loss after epoque  100  is  0.0492968404146\n",
      "The loss after epoque  200  is  0.0277425461316\n",
      "The loss after epoque  300  is  0.021482160834\n",
      "The loss after epoque  0  is  0.612300734628\n",
      "The loss after epoque  100  is  0.0364763413811\n",
      "The loss after epoque  200  is  0.0226601347814\n",
      "The loss after epoque  300  is  0.018243343968\n",
      "The loss after epoque  0  is  0.587296715005\n",
      "The loss after epoque  100  is  0.0305328991508\n",
      "The loss after epoque  200  is  0.0201282819338\n",
      "The loss after epoque  300  is  0.0167234822095\n",
      "The loss after epoque  0  is  0.771803029409\n",
      "The loss after epoque  100  is  0.431925838554\n",
      "The loss after epoque  200  is  0.415892505417\n",
      "The loss after epoque  300  is  0.397476563154\n",
      "The loss after epoque  0  is  0.758179790466\n",
      "The loss after epoque  100  is  0.397398709547\n",
      "The loss after epoque  200  is  0.286250326373\n",
      "The loss after epoque  300  is  0.165806650576\n",
      "The loss after epoque  0  is  0.745542156705\n",
      "The loss after epoque  100  is  0.330377944069\n",
      "The loss after epoque  200  is  0.139682803225\n",
      "The loss after epoque  300  is  0.077604560005\n",
      "The loss after epoque  0  is  0.733759219254\n",
      "The loss after epoque  100  is  0.240036357068\n",
      "The loss after epoque  200  is  0.0848686785942\n",
      "The loss after epoque  300  is  0.0530788673648\n",
      "The loss after epoque  0  is  0.722730955579\n",
      "The loss after epoque  100  is  0.165324237073\n",
      "The loss after epoque  200  is  0.0624857673887\n",
      "The loss after epoque  300  is  0.0420042597181\n",
      "The loss after epoque  0  is  0.775886838105\n",
      "The loss after epoque  100  is  0.460545782871\n",
      "The loss after epoque  200  is  0.429401091679\n",
      "The loss after epoque  300  is  0.422126716426\n",
      "The loss after epoque  0  is  0.769761891603\n",
      "The loss after epoque  100  is  0.422109486896\n",
      "The loss after epoque  200  is  0.40014193191\n",
      "The loss after epoque  300  is  0.357915182017\n",
      "The loss after epoque  0  is  0.763835057236\n",
      "The loss after epoque  100  is  0.409039873071\n",
      "The loss after epoque  200  is  0.339347125344\n",
      "The loss after epoque  300  is  0.232621781884\n",
      "The loss after epoque  0  is  0.758092911092\n",
      "The loss after epoque  100  is  0.388525190292\n",
      "The loss after epoque  200  is  0.253813469316\n",
      "The loss after epoque  300  is  0.139477031342\n",
      "The loss after epoque  0  is  0.752533024614\n",
      "The loss after epoque  100  is  0.357486822786\n",
      "The loss after epoque  200  is  0.177629289426\n",
      "The loss after epoque  300  is  0.0957604405396\n",
      "[[  1.35869565   1.08695652   1.08695652   1.35869565   1.35869565   0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [ 19.83695652   1.63043478   1.35869565   0.81521739   0.81521739   0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [ 21.73913043  14.13043478   5.16304348   1.63043478   1.35869565   0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.           0.           0.\n",
      "    0.           0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "ntrain = 2* (data.shape[0] // 3)\n",
    "\n",
    "inds = [i for i in range(data.shape[0])]\n",
    "np.random.seed(123)\n",
    "np.random.shuffle(inds)\n",
    "\n",
    "test_inds = inds[:ntrain]\n",
    "validation_inds = inds[ntrain:]\n",
    "\n",
    "#On définit l'ensemble d'entraînement et l'ensemble de validation\n",
    "train_data = data[test_inds,]\n",
    "validation_data = data[validation_inds,]\n",
    "print(train_data.shape)\n",
    "print(validation_data.shape)\n",
    "\n",
    "#Optimisation des paramètres de capacité: nbre couches cachées et lambdas\n",
    "lambdas = np.array([[0., 0.],\n",
    "       [0., 0.]])\n",
    "\n",
    "\n",
    "\n",
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    while i < stop:\n",
    "        yield i\n",
    "        i += step\n",
    "        \n",
    "erreurs = np.zeros([15,10])\n",
    "i = 0\n",
    "for K in [20, 100, 200]:#range(20,train_data.shape[0],200):\n",
    "    j = 0\n",
    "    for eta in frange(0.01,0.1,0.02):\n",
    "        nn = NeuralNet_loop(2,20,2,lambdas, K)   \n",
    "        nn.train(train_data,400,eta)  \n",
    "        erreurs[i,j] = taux_erreur(nn, validation_data)\n",
    "        j = j + 1\n",
    "    i = i + 1\n",
    "print(erreurs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage des régions de décisions pour plusieurs valeurs d'hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:43: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss after epoque  0  is  0.576955713386\n",
      "The loss after epoque  100  is  0.0284379475261\n",
      "The loss after epoque  200  is  0.019198183737\n",
      "The loss after epoque  300  is  0.0162175987163\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAFkCAYAAAAuUDI+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa4e4ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambdas = np.array([[0., 0.],\n",
    "       [0., 0.]])\n",
    "nn = NeuralNet_loop(2,20,2,lambdas, 20)   \n",
    "nn.train(train_data,400,0.1) \n",
    "gridplot(nn, train_data, validation_data, 50)\n",
    "#print(nn.W1)\n",
    "#print(nn.W2)\n",
    "#print(nn.b1)\n",
    "#print(nn.b2)\n",
    "print(taux_erreurs(nn, validation_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implémentation du calcul de gradient avec expressions matricielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{W}^{(1)} \\in \\mathbb{R}^{d_h \\times d}$, $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ et $\\mathbf{B}^{(1)} \\in \\mathbb{R}^{d_h \\times n}$\n",
    "\n",
    "$$\\mathbf{h}^{a} = \\mathbf{W}^{(1)}\\mathbf{X}^{\\top} + \\mathbf{B}^{(1)} \\in \\mathbb{R}^{d_h \\times n}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetVectorized:\n",
    "    \n",
    "    def __init__(self, n_input, n_hidden, n_out, lambdas, K=1):\n",
    "        \n",
    "        self.n_in = n_input\n",
    "        self.n_h = n_hidden\n",
    "        self.n_o = n_out\n",
    "        self.lambdas = lambdas\n",
    "        self.K = K\n",
    "        \n",
    "        low_bound = -1 / np.sqrt([self.n_in, self.n_h])\n",
    "        up_bound = 1 / np.sqrt([self.n_in, self.n_h])\n",
    "        \n",
    "        # Initialize the parameters\n",
    "        np.random.seed(123)\n",
    "        self.W1 = np.random.uniform(low_bound[0], up_bound[0], size=(self.n_h, self.n_in))  # d_h x d\n",
    "        self.W2 = np.random.uniform(low_bound[1], up_bound[1], size=(self.n_o, self.n_h))  # m x d_h\n",
    "        self.b1 = np.zeros(self.n_h)  # dimension d_h\n",
    "        self.b2 = np.zeros(self.n_o) # dimension m\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        '''\n",
    "        Computes activations for every layer\n",
    "        X: input data set\n",
    "        '''\n",
    "        self.ha = self.W1.dot(X.T) + self.b1.reshape(self.n_h, 1)\n",
    "        self.hs = relu(self.ha)\n",
    "        self.oa = self.W2.dot(self.hs) + self.b2.reshape(self.n_o, 1)\n",
    "        self.os = np.transpose(softmax(self.oa.T))\n",
    "            \n",
    "    def bprop(self, X, Y):\n",
    "        '''\n",
    "        Computes the gradients, must be executed after fprop\n",
    "        X: Input data set\n",
    "        Y: targets\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "                      \n",
    "        grad_oa = self.os - onehot_matrix(self.n_o, Y)\n",
    "        grad_b2 = np.sum(grad_oa, axis =1) # m x n\n",
    "        grad_W2 = np.dot(grad_oa, self.hs.T) # sum of gradients grad_W2 for each example\n",
    "        grad_hs = self.W2.T.dot(grad_oa) # d_h x n\n",
    "        grad_ha = grad_hs * (self.ha > 0) # d_h x n\n",
    "        grad_W1 = np.dot(grad_ha, X) # sum of gradients grad_W1 for each example\n",
    "        grad_b1 = np.sum(grad_ha, axis =1) # d_h x n\n",
    "        \n",
    "        return grad_W1 / n, grad_W2 / n, grad_b1 / n, grad_b2 / n #returns average of the gradient\n",
    "    \n",
    "    def compute_loss(self, Y):\n",
    "        loss = 0\n",
    "        for i in range(Y.shape[0]):\n",
    "            loss = loss -np.log(self.os[Y[i],i])\n",
    "        return loss\n",
    "    \n",
    "    def train(self, train_data, max_iter, eta=0.05):\n",
    "        \n",
    "        n_batches = int(np.ceil(train_data.shape[0]/self.K)) # number of batches\n",
    "        \n",
    "        for i in range(max_iter):\n",
    "            for j in range(0,train_data.shape[0],self.K):\n",
    "                batch = train_data[j:j+self.K]\n",
    "                \n",
    "                self.fprop(batch[:,:-1])\n",
    "                grad_W1_mean, grad_W2_mean, grad_b1_mean, grad_b2_mean = self.bprop(batch[:,:-1], batch[:,-1]) \n",
    "                \n",
    "                n = len(batch)\n",
    "                \n",
    "                #regularization\n",
    "                penality_grad_W1 = self.lambdas[0][0] * np.sign(self.W1) + 2 * self.lambdas[0][1] * self.W1\n",
    "                penality_grad_W2 = self.lambdas[1][0] * np.sign(self.W2) + 2 * self.lambdas[1][1] * self.W2\n",
    "                \n",
    "                self.W1 = self.W1 - eta * (grad_W1_mean + penality_grad_W1)\n",
    "                self.W2 = self.W2 - eta * (grad_W2_mean + penality_grad_W2)\n",
    "                self.b1 = self.b1 - eta * grad_b1_mean\n",
    "                self.b2 = self.b2 - eta * grad_b2_mean\n",
    "                    \n",
    "    def compute_predictions(self, test_data):\n",
    "        self.fprop(test_data)\n",
    "        pred = self.os\n",
    "\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7. Comparaison du gradient des deux implémentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:43: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:15: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06451412 -0.06900175]\n",
      " [ 0.04133331 -0.04728092]]\n",
      "[[ 0.06451412 -0.06900175]\n",
      " [ 0.04133331 -0.04728092]]\n",
      "[[  1.38777878e-17   6.93889390e-17]\n",
      " [ -1.38777878e-17  -2.77555756e-17]]\n",
      "[[-0.10498392  0.0524078 ]\n",
      " [ 0.10498392 -0.0524078 ]]\n",
      "[[-0.10498392  0.0524078 ]\n",
      " [ 0.10498392 -0.0524078 ]]\n",
      "[[ -1.11022302e-16   1.38777878e-17]\n",
      " [  1.11022302e-16  -6.93889390e-18]]\n",
      "[ 0.05953552 -0.03744815]\n",
      "[ 0.05953552 -0.03744815]\n",
      "[  2.08166817e-17  -2.08166817e-17]\n",
      "[-0.06300307  0.06300307]\n",
      "[-0.06300307  0.06300307]\n",
      "[ -1.38777878e-17   1.38777878e-17]\n",
      "[[ 0.06451412 -0.06900175]\n",
      " [ 0.04133331 -0.04728092]]\n",
      "[[ 0.06451412 -0.06900175]\n",
      " [ 0.04133331 -0.04728092]]\n",
      "[[  1.38777878e-17   6.93889390e-17]\n",
      " [ -1.38777878e-17  -2.77555756e-17]]\n",
      "[[-0.10498392  0.0524078 ]\n",
      " [ 0.10498392 -0.0524078 ]]\n",
      "[[-0.10498392  0.0524078 ]\n",
      " [ 0.10498392 -0.0524078 ]]\n",
      "[[ -1.11022302e-16   1.38777878e-17]\n",
      " [  1.11022302e-16  -6.93889390e-18]]\n",
      "[ 0.05953552 -0.03744815]\n",
      "[ 0.05953552 -0.03744815]\n",
      "[  2.08166817e-17  -2.08166817e-17]\n",
      "[-0.06300307  0.06300307]\n",
      "[-0.06300307  0.06300307]\n",
      "[ -1.38777878e-17   1.38777878e-17]\n"
     ]
    }
   ],
   "source": [
    "#initialize a neural network of each implementation, with K=1 and K=10\n",
    "for K in range(1,11,9):\n",
    "    lambdas = np.array([[0, 0],\n",
    "           [0, 0]])\n",
    "    nn_loop = NeuralNet_loop(2,2,2,lambdas, K)\n",
    "    nn_matrix = NeuralNetVectorized(2,2,2,lambdas,K)\n",
    "    \n",
    "    #gradient with loop implementation\n",
    "    grad_W1_loop, grad_W2_loop, grad_b1_loop, grad_b2_loop, _ = nn_loop.bprop(train_data[:,:-1],train_data[:,-1])\n",
    "    \n",
    "    #gradient with matrix multiplications implementation\n",
    "    nn_matrix.fprop(train_data[:,:-1])\n",
    "    grad_W1_mat, grad_W2_mat, grad_b1_mat, grad_b2_mat = nn_matrix.bprop(train_data[:,:-1],train_data[:,-1])\n",
    "    \n",
    "    #print comparison of all gradients\n",
    "    print(grad_W1_loop)\n",
    "    print(grad_W1_mat)\n",
    "    print(grad_W1_loop - grad_W1_mat)\n",
    "\n",
    "    print(grad_W2_loop)\n",
    "    print(grad_W2_mat)\n",
    "    print(grad_W2_loop - grad_W2_mat)\n",
    "\n",
    "    print(grad_b1_loop)\n",
    "    print(grad_b1_mat)\n",
    "    print(grad_b1_loop - grad_b1_mat)\n",
    "\n",
    "    print(grad_b2_loop)\n",
    "    print(grad_b2_mat)\n",
    "    print(grad_b2_loop - grad_b2_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparaison du temps de calcul pour une époque quand K=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xa6812b0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8cb7b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('mnist-original', data_home='/u/dift3395/sklearn_data')\n",
    "\n",
    "plt.imshow(mnist.data[21455,:].reshape(28, 28), interpolation=\"nearest\", cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diviser le dataset MNIST en ensembles train, valid et test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(50000, 785)\n",
      "(732, 3)\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.permutation(len(mnist['target']))\n",
    "\n",
    "print(mnist['data'].shape)\n",
    "\n",
    "X_train = mnist['data'][indices][:50000]/255.\n",
    "X_valid = mnist['data'][indices][50000:60000]/255.\n",
    "X_test = mnist['data'][indices][60000:]/255.\n",
    "y_train = mnist['target'][indices][:50000]\n",
    "y_valid = mnist['target'][indices][50000:60000]\n",
    "y_test = mnist['target'][indices][60000:]\n",
    "\n",
    "#from keras.utils import np_utils\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_valid = np_utils.to_categorical(y_valid)\n",
    "#y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "#concatenate data and target into one np.array\n",
    "train = np.concatenate((X_train, np.reshape(y_train, (50000,1))), axis=1)\n",
    "valid = np.concatenate((X_valid, np.reshape(y_valid, (10000,1))), axis=1)\n",
    "test = np.concatenate((X_test, np.reshape(y_test, (10000,1))), axis=1)\n",
    "\n",
    "print(train.shape)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:43: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834191084799\n",
      "--- 5.833999872207642 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zimmae\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:15: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.6530001163482666 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#initializing neural networks\n",
    "nn_loop = NeuralNet_loop(784,20,10,lambdas,100)\n",
    "nn_matrix = NeuralNetVectorized(784,20,10,lambdas,100)\n",
    "\n",
    "#train both neural networks\n",
    "import time\n",
    "start_time = time.time()\n",
    "nn_loop.train(train,1,0.05)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "nn_matrix.train(train,1,0.05)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calcul de taux d'erreur de classification sur MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification de la classe NeuralNetworkVectorized pour calculer les valeurs recherchées à chaque époque de la phase l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetVectorized2:\n",
    "    \n",
    "    def __init__(self, n_input, n_hidden, n_out, lambdas, K=1):\n",
    "        \n",
    "        self.n_in = n_input\n",
    "        self.n_h = n_hidden\n",
    "        self.n_o = n_out\n",
    "        self.lambdas = lambdas\n",
    "        self.K = K\n",
    "        \n",
    "        low_bound = -1 / np.sqrt([self.n_in, self.n_h])\n",
    "        up_bound = 1 / np.sqrt([self.n_in, self.n_h])\n",
    "        \n",
    "        # Initialize the parameters\n",
    "        np.random.seed(123)\n",
    "        self.W1 = np.random.uniform(low_bound[0], up_bound[0], size=(self.n_h, self.n_in))  # d_h x d\n",
    "        self.W2 = np.random.uniform(low_bound[1], up_bound[1], size=(self.n_o, self.n_h))  # m x d_h\n",
    "        self.b1 = np.zeros(self.n_h)  # dimension d_h\n",
    "        self.b2 = np.zeros(self.n_o) # dimension m\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        '''\n",
    "        Computes activations for every layer\n",
    "        X: input data set\n",
    "        '''\n",
    "        self.ha = self.W1.dot(X.T) + self.b1.reshape(self.n_h, 1)\n",
    "        self.hs = relu(self.ha)\n",
    "        self.oa = self.W2.dot(self.hs) + self.b2.reshape(self.n_o, 1)\n",
    "        self.os = np.transpose(softmax(self.oa.T))\n",
    "            \n",
    "    def bprop(self, X, Y):\n",
    "        '''\n",
    "        Computes the gradients, must be executed after fprop\n",
    "        X: Input data set\n",
    "        Y: targets\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "                      \n",
    "        grad_oa = self.os - onehot_matrix(self.n_o, Y)\n",
    "        grad_b2 = np.sum(grad_oa, axis =1) # m x n\n",
    "        grad_W2 = np.dot(grad_oa, self.hs.T) # sum of gradients grad_W2 for each example\n",
    "        grad_hs = self.W2.T.dot(grad_oa) # d_h x n\n",
    "        grad_ha = grad_hs * (self.ha > 0) # d_h x n\n",
    "        grad_W1 = np.dot(grad_ha, X) # sum of gradients grad_W1 for each example\n",
    "        grad_b1 = np.sum(grad_ha, axis =1) # d_h x n\n",
    "        \n",
    "        return grad_W1 / n, grad_W2 / n, grad_b1 / n, grad_b2 / n #returns average of the gradient\n",
    "    \n",
    "    def compute_loss(self, Y):\n",
    "        ind = [i for i in range(Y.shape[0])]\n",
    "        loss = self.os[Y.astype(int),ind]\n",
    "        return np.sum(-np.log(loss))\n",
    "    \n",
    "    def train(self, train_data, valid_data, test_data, max_iter, eta=0.05):\n",
    "        \n",
    "        n_batches = int(np.ceil(train_data.shape[0]/self.K)) # number of batches\n",
    "        \n",
    "        for i in range(max_iter):\n",
    "            for j in range(0,train_data.shape[0],self.K):\n",
    "                batch = train_data[j:j+self.K]\n",
    "                \n",
    "                self.fprop(batch[:,:-1])\n",
    "                grad_W1_mean, grad_W2_mean, grad_b1_mean, grad_b2_mean = self.bprop(batch[:,:-1], batch[:,-1]) \n",
    "                \n",
    "                n = len(batch)\n",
    "                \n",
    "                #regularization\n",
    "                penality_grad_W1 = self.lambdas[0][0] * np.sign(self.W1) + 2 * self.lambdas[0][1] * self.W1\n",
    "                penality_grad_W2 = self.lambdas[1][0] * np.sign(self.W2) + 2 * self.lambdas[1][1] * self.W2\n",
    "                \n",
    "                self.W1 = self.W1 - eta * (grad_W1_mean + penality_grad_W1)\n",
    "                self.W2 = self.W2 - eta * (grad_W2_mean + penality_grad_W2)\n",
    "                self.b1 = self.b1 - eta * grad_b1_mean\n",
    "                self.b2 = self.b2 - eta * grad_b2_mean\n",
    "                    \n",
    "            self.write_in_file(train_data, valid_data, test_data)\n",
    "                    \n",
    "    def compute_predictions(self, test_data):\n",
    "        self.fprop(test_data)\n",
    "        pred = self.os\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def write_in_file(self,train_data,valid_data,test_data):\n",
    "        train_prob = self.compute_predictions(train_data[:,:-1])\n",
    "        train_classe_pred = np.argmax(train_prob, axis = 0)  \n",
    "        valid_prob = self.compute_predictions(valid_data[:,:-1])\n",
    "        valid_classe_pred = np.argmax(valid_prob, axis = 0)\n",
    "        test_prob = self.compute_predictions(test_data[:,:-1])\n",
    "        test_classe_pred = np.argmax(test_prob, axis = 0)\n",
    "        classif_erreur_train = 100*float(sum(sum([train_classe_pred != train_data[:,-1]])))/train_data.shape[0]\n",
    "        classif_erreur_valid = 100*float(sum(sum([valid_classe_pred != valid_data[:,-1]])))/valid_data.shape[0]\n",
    "        classif_erreur_test = 100*float(sum(sum([test_classe_pred != test_data[:,-1]])))/test_data.shape[0]\n",
    "        self.fprop(train_data[:,:-1])\n",
    "        loss_train = self.compute_loss(train_data[:,-1])\n",
    "        print(classif_erreur_train)\n",
    "        print(classif_erreur_test)\n",
    "        print(classif_erreur_valid)\n",
    "        print(loss_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 7 2 2 6 7 0 0 9 7 3 8 0 6 8 8 8 8 3]\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.array([[0.01, 0.01],\n",
    "           [0.01, 0.01]])\n",
    "nn_mnist = NeuralNetVectorized2(784,64,10,lambdas,train.shape[0])\n",
    "\n",
    "nn_mnist.fprop(train[:,:-1])\n",
    "#print(nn_mnist.ha)\n",
    "#print(nn_mnist.hs)\n",
    "#print(nn_mnist.oa)\n",
    "#print(nn_mnist.os)\n",
    "print(nn_mnist.compute_loss(train[:,-1]))\n",
    "nn_mnist.train(train,test,valid,10,0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
